{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uT0ZkzxQFPqo",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L4nmLCFf3HoC",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Step 0: Package Installation & setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pV0dx8Ny1q64",
    "outputId": "0f50a253-58ad-48bf-e31e-573ab6e65926"
   },
   "outputs": [],
   "source": [
    "# 1. Install nx-arangodb via pip\n",
    "# Github: https://github.com/arangodb/nx-arangodb\n",
    "\n",
    "!pip install nx-arangodb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lOCF_C_8FPqs",
    "outputId": "051e2727-bc58-4f34-9e1e-c403d6855be1"
   },
   "outputs": [],
   "source": [
    "# 2. Check if you have an NVIDIA GPU\n",
    "# Note: If this returns \"command not found\", then GPU-based algorithms via cuGraph are unavailable\n",
    "\n",
    "!nvidia-smi\n",
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uQq25vXFFPqs",
    "outputId": "8fe99e2e-9cad-4fec-9eb0-558ea62bb504"
   },
   "outputs": [],
   "source": [
    "# 3. Install nx-cugraph via pip\n",
    "# Note: Only enable this installation if the step above is working!\n",
    "\n",
    "%pip install nx-cugraph-cu12 --extra-index-url https://pypi.nvidia.com # Requires CUDA-capable GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FuhKpmcWFPqs",
    "outputId": "fb847911-79d3-49cc-f102-75d9914e7e5d"
   },
   "outputs": [],
   "source": [
    "# 4. Install LangChain & LangGraph\n",
    "\n",
    "%pip install --upgrade langchain langchain-community langchain-deepseek langgraph tree-sitter==0.21.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "121wxwbzFPqs",
    "outputId": "4ac88786-dfcd-46cb-b785-251c080a790d"
   },
   "outputs": [],
   "source": [
    "# 5. Import the required modules\n",
    "import networkx as nx\n",
    "import nx_arangodb as nxadb\n",
    "\n",
    "from arango import ArangoClient\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "import re\n",
    "import threading\n",
    "\n",
    "\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.graphs import ArangoGraph\n",
    "from langchain_community.chains.graph_qa.arangodb import ArangoGraphQAChain\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "from git import Repo\n",
    "from tree_sitter import Language, Parser\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from langchain_deepseek import ChatDeepSeek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LzuXc2pBFPqs",
    "outputId": "c8c8c153-459f-43f0-bf71-af3c3c528fc4"
   },
   "outputs": [],
   "source": [
    "# 6. Connect to the ArangoDB database\n",
    "\n",
    "db = ArangoClient(hosts=\"https://762f172f4012.arangodb.cloud:8529\").db(username=\"root\", password=\"YOURPASSWORD\", verify=True)\n",
    "\n",
    "print(db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Eu1jbD6FPqt",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Step 1: Choosing & preparing dataset for NetworkX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dfx5vaqx2bWl"
   },
   "outputs": [],
   "source": [
    "# 1. Download the dataset\n",
    "# 2. Parse the repo to import into graph\n",
    "# Clone the repo\n",
    "def clone_repo(repo_url, repo_path=\"repo\"):\n",
    "    if not os.path.exists(repo_path):\n",
    "        print(f\"Cloning repository: {repo_url}\")\n",
    "        Repo.clone_from(repo_url, repo_path)\n",
    "    else:\n",
    "        print(\"Repository already exists. Skipping clone.\")\n",
    "    return repo_path\n",
    "\n",
    "# Traverse through repo files\n",
    "def traverse_files(repo_path, extensions=None):\n",
    "    files = []\n",
    "    for root, _, filenames in os.walk(repo_path):\n",
    "        for filename in filenames:\n",
    "            if extensions and not any(filename.endswith(ext) for ext in extensions):\n",
    "                continue\n",
    "            file_path = os.path.join(root, filename)\n",
    "            files.append(file_path)\n",
    "    return files\n",
    "\n",
    "def traverse_tree(node):\n",
    "    \"\"\"Helper function to traverse all descendants of a node.\"\"\"\n",
    "    yield node\n",
    "    for child in node.children:\n",
    "        yield from traverse_tree(child)\n",
    "\n",
    "# Setup Tree-sitter parser\n",
    "def setup_tree_sitter():\n",
    "    \"\"\"Set up the tree-sitter parser for Python, avoiding redundant builds.\"\"\"\n",
    "    build_path = \"build/my-languages.so\"\n",
    "    repo_path = \"tree-sitter-repos/tree-sitter-python\"\n",
    "\n",
    "    # Check if the shared library already exists\n",
    "    if not os.path.exists(build_path):\n",
    "        print(f\"Building Tree-sitter language library at {build_path}...\")\n",
    "\n",
    "        # Ensure the repository exists before building\n",
    "        if not os.path.exists(repo_path):\n",
    "            print(\"Cloning the Tree-sitter Python repository...\")\n",
    "            subprocess.run([\"git\", \"clone\", \"https://github.com/tree-sitter/tree-sitter-python\", repo_path], check=True)\n",
    "\n",
    "        # Build the library\n",
    "        Language.build_library(\n",
    "            build_path,\n",
    "            [repo_path]\n",
    "        )\n",
    "    else:\n",
    "        print(\"Tree-sitter language library already exists. Skipping build.\")\n",
    "\n",
    "    return Language(build_path, \"python\")\n",
    "\n",
    "# Initialize Tree-sitter\n",
    "def load_tree_sitter():\n",
    "    language = setup_tree_sitter()\n",
    "    parser = Parser()\n",
    "    parser.set_language(language)\n",
    "    return parser\n",
    "\n",
    "# Parse source code using Tree-sitter\n",
    "def parse_code(file_path, parser):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        code = f.read()\n",
    "    tree = parser.parse(bytes(code, \"utf8\"))\n",
    "    return tree\n",
    "\n",
    "def build_graph(files, parser):\n",
    "    \"\"\"Builds a directed graph representing the structure of the parsed files with metadata.\"\"\"\n",
    "    G = nx.DiGraph()\n",
    "    global_vars = []\n",
    "    class_methods = {}  # Track class methods for easier lookup\n",
    "\n",
    "    # First pass: Collect class and method definitions\n",
    "    for file in files:\n",
    "        tree = parse_code(file, parser)\n",
    "        root_node = tree.root_node\n",
    "        for node in root_node.children:\n",
    "            if node.type == \"class_definition\":\n",
    "                class_name_node = node.child_by_field_name(\"name\")\n",
    "                if class_name_node:\n",
    "                    class_name = class_name_node.text.decode(\"utf8\")\n",
    "                    # Store methods of this class\n",
    "                    for class_child in node.children:\n",
    "                        if class_child.type == \"block\":\n",
    "                            for method in class_child.children:\n",
    "                                if method.type == \"function_definition\":\n",
    "                                    method_name_node = method.child_by_field_name(\"name\")\n",
    "                                    if method_name_node:\n",
    "                                        method_name = method_name_node.text.decode(\"utf8\")\n",
    "                                        full_method_name = f\"{class_name}.{method_name}\"\n",
    "                                        # Store class methods for lookup\n",
    "                                        if class_name not in class_methods:\n",
    "                                            class_methods[class_name] = []\n",
    "                                        class_methods[class_name].append(method_name)\n",
    "\n",
    "    # Second pass: Build the actual graph\n",
    "    for file in files:\n",
    "        tree = parse_code(file, parser)\n",
    "        root_node = tree.root_node\n",
    "        file_size = os.path.getsize(file)\n",
    "        mod_time = os.path.getmtime(file)\n",
    "        imports = extract_imports(root_node)\n",
    "        # Add file node with metadata\n",
    "        G.add_node(file, type=\"file\", name=file, size=file_size, modification_time=mod_time, imports=imports)\n",
    "\n",
    "        # Track import relationships between files\n",
    "        imported_classes = {}\n",
    "        for imp in imports:\n",
    "            if imp.startswith(\"from \"):\n",
    "                parts = imp.split(\" import \")\n",
    "                if len(parts) == 2:\n",
    "                    module_path = parts[0][5:]  # Remove \"from \"\n",
    "                    imported_items = [item.strip() for item in parts[1].split(\",\")]\n",
    "                    for item in imported_items:\n",
    "                        imported_classes[item] = module_path\n",
    "\n",
    "        for node in root_node.children:\n",
    "            if node.type == \"class_definition\":\n",
    "                process_class_definition(node, file, G, class_methods)\n",
    "            elif node.type == \"function_definition\":\n",
    "                process_function_definition(node, file, G, class_methods, imported_classes)\n",
    "            elif node.type == \"expression_statement\":\n",
    "                process_global_variable(node, file, G, global_vars)\n",
    "\n",
    "    return G\n",
    "\n",
    "def extract_imports(root_node):\n",
    "    \"\"\"Extracts import statements from the root node of a file.\"\"\"\n",
    "    return [node.text.decode(\"utf8\") for node in root_node.children if node.type == \"import_statement\"]\n",
    "\n",
    "def process_class_definition(node, file, G, class_methods):\n",
    "    \"\"\"Processes a class definition node and adds it to the graph.\"\"\"\n",
    "    class_name_node = node.child_by_field_name(\"name\")\n",
    "    if not class_name_node:\n",
    "        return\n",
    "    class_name = class_name_node.text.decode(\"utf8\")\n",
    "    docstring = extract_docstring(node)\n",
    "    num_methods = sum(1 for n in node.children if n.type == \"function_definition\")\n",
    "    inheritance = extract_inheritance(node)\n",
    "    G.add_node(class_name, type=\"class\", name=class_name, file=file, docstring=docstring, number_of_methods=num_methods, inheritance=inheritance)\n",
    "    G.add_edge(file, class_name, relation=\"contains\")\n",
    "\n",
    "    # Process methods within the class\n",
    "    for class_child in node.children:\n",
    "        if class_child.type == \"block\":\n",
    "            for method in class_child.children:\n",
    "                if method.type == \"function_definition\":\n",
    "                    process_method_definition(method, class_name, file, G, class_methods)\n",
    "\n",
    "\n",
    "def extract_inheritance(node):\n",
    "    \"\"\"Extracts inheritance details if present.\"\"\"\n",
    "    base_class_node = node.child_by_field_name(\"superclass\")\n",
    "    return base_class_node.text.decode(\"utf8\") if base_class_node else \"None\"\n",
    "\n",
    "def extract_docstring(node):\n",
    "    \"\"\"Extracts the docstring of a class or function if present.\"\"\"\n",
    "    for child in node.children:\n",
    "        if child.type == \"string\":\n",
    "            return child.text.decode(\"utf8\")\n",
    "    return \"No docstring\"\n",
    "\n",
    "def process_method_definition(node, class_name, file, G, class_methods):\n",
    "    \"\"\"Processes a method inside a class and adds it to the graph.\"\"\"\n",
    "    method_name_node = node.child_by_field_name(\"name\")\n",
    "    if not method_name_node:\n",
    "        return\n",
    "    method_name = method_name_node.text.decode(\"utf8\")\n",
    "    full_method_name = f\"{class_name}.{method_name}\"\n",
    "    parameters = extract_parameters(node)\n",
    "    return_type = extract_return_type(node)\n",
    "    docstring = extract_docstring(node)\n",
    "    G.add_node(full_method_name, type=\"method\", name=full_method_name, file=file, class_=class_name, parameters=parameters, return_type=return_type, docstring=docstring)\n",
    "    G.add_edge(class_name, full_method_name, relation=\"has_method\")\n",
    "\n",
    "    # Detect function calls within the method\n",
    "    block = node.child_by_field_name(\"body\")\n",
    "    if block:\n",
    "        instance_mapping = {\"self\": class_name}  # Map 'self' to the class name\n",
    "        detect_function_calls(block, full_method_name, G, instance_mapping, class_methods)\n",
    "\n",
    "def extract_parameters(node):\n",
    "    \"\"\"Extracts function parameters.\"\"\"\n",
    "    param_node = node.child_by_field_name(\"parameters\")\n",
    "    if not param_node:\n",
    "        return []\n",
    "    return [p.text.decode(\"utf8\") for p in param_node.children if p.type == \"identifier\"]\n",
    "\n",
    "def extract_return_type(node):\n",
    "    \"\"\"Extracts return type if annotated.\"\"\"\n",
    "    return_node = node.child_by_field_name(\"return_type\")\n",
    "    return return_node.text.decode(\"utf8\") if return_node else \"Unknown\"\n",
    "\n",
    "def process_function_definition(node, file, G, class_methods, imported_classes):\n",
    "    \"\"\"Processes a function definition and adds it to the graph.\"\"\"\n",
    "    func_name_node = node.child_by_field_name(\"name\")\n",
    "    if not func_name_node:\n",
    "        return\n",
    "    func_name = func_name_node.text.decode(\"utf8\")\n",
    "    parameters = extract_parameters(node)\n",
    "    return_type = extract_return_type(node)\n",
    "    docstring = extract_docstring(node)\n",
    "    G.add_node(func_name, type=\"function\", name=func_name, file=file, parameters=parameters, return_type=return_type, docstring=docstring)\n",
    "    G.add_edge(file, func_name, relation=\"contains\")\n",
    "\n",
    "    # Process function body to detect class instantiations and method calls\n",
    "    block = node.child_by_field_name(\"body\")\n",
    "    if block:\n",
    "        instance_mapping = {}\n",
    "\n",
    "        # First, find all class instantiations\n",
    "        for descendant in traverse_tree(block):\n",
    "            if descendant.type == \"assignment\":\n",
    "                left = descendant.child_by_field_name(\"left\")\n",
    "                right = descendant.child_by_field_name(\"right\")\n",
    "\n",
    "                if left and right and right.type == \"call\":\n",
    "                    var_name = left.text.decode(\"utf8\")\n",
    "                    call_func = right.child_by_field_name(\"function\")\n",
    "\n",
    "                    if call_func:\n",
    "                        class_name = call_func.text.decode(\"utf8\")\n",
    "                        # Check if this is a class we know about (imported or defined)\n",
    "                        if class_name in imported_classes or class_name in class_methods:\n",
    "                            instance_mapping[var_name] = class_name\n",
    "\n",
    "        # Then detect function calls with the instance mapping\n",
    "        detect_function_calls(block, func_name, G, instance_mapping, class_methods)\n",
    "\n",
    "def detect_class_instantiations(node, instance_mapping):\n",
    "    \"\"\"Detects variable assignments to class instances and stores the mapping.\"\"\"\n",
    "    for child in node.children:\n",
    "        if child.type == \"assignment\":\n",
    "            var_name_node = child.child_by_field_name(\"left\")\n",
    "            value_node = child.child_by_field_name(\"right\")\n",
    "\n",
    "            if var_name_node and value_node and value_node.type == \"call\":\n",
    "                class_name_node = value_node.child_by_field_name(\"function\")\n",
    "                if class_name_node:\n",
    "                    var_name = var_name_node.text.decode(\"utf8\")\n",
    "                    class_name = class_name_node.text.decode(\"utf8\")\n",
    "                    instance_mapping[var_name] = class_name  # Map instance variable to class\n",
    "\n",
    "\n",
    "def detect_function_calls(node, caller, G, instance_mapping, class_methods):\n",
    "    \"\"\"Improved function to detect and resolve method calls including those on class instances.\"\"\"\n",
    "    for descendant in traverse_tree(node):\n",
    "        if descendant.type == \"call\":\n",
    "            call_func = descendant.child_by_field_name(\"function\")\n",
    "            if call_func:\n",
    "                call_name = call_func.text.decode(\"utf8\")\n",
    "                resolved_call = call_name\n",
    "\n",
    "                # If it's a method call on an instance (contains a dot)\n",
    "                if \".\" in call_name:\n",
    "                    instance_var, method_name = call_name.split(\".\", 1)\n",
    "\n",
    "                    # If we have this instance in our mapping\n",
    "                    if instance_var in instance_mapping:\n",
    "                        class_name = instance_mapping[instance_var]\n",
    "\n",
    "                        # Check if this method exists in the class\n",
    "                        if class_name in class_methods and method_name in class_methods[class_name]:\n",
    "                            resolved_call = f\"{class_name}.{method_name}\"\n",
    "\n",
    "                # Add the edge showing the function call relationship\n",
    "                call_line_number = descendant.start_point[0] + 1\n",
    "                G.add_edge(caller, resolved_call, relation=\"calls\", line_number=call_line_number)\n",
    "\n",
    "\n",
    "\n",
    "def process_global_variable(node, file, G, global_vars):\n",
    "    \"\"\"Processes a global variable declaration and adds it to the graph.\"\"\"\n",
    "    for child in node.children:\n",
    "        if child.type == \"assignment\":\n",
    "            var_name_node = child.child_by_field_name(\"left\")\n",
    "            if var_name_node:\n",
    "                var_name = var_name_node.text.decode(\"utf8\")\n",
    "                data_type = infer_data_type(child)\n",
    "                G.add_node(var_name, type=\"variable\", name=var_name, file=file, data_type=data_type)\n",
    "                G.add_edge(file, var_name, relation=\"defines\")\n",
    "                global_vars.append(f\"{var_name} in {file}\")\n",
    "\n",
    "def infer_data_type(assignment_node):\n",
    "    \"\"\"Infers the data type of a variable if possible.\"\"\"\n",
    "    value_node = assignment_node.child_by_field_name(\"right\")\n",
    "    if not value_node:\n",
    "        return \"Unknown\"\n",
    "    if value_node.type in [\"string\", \"integer\", \"float\", \"boolean\"]:\n",
    "        return value_node.type\n",
    "    return \"Complex\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o5J_0BrSvBcJ",
    "outputId": "eddf6a6a-d026-4e61-e41c-f56a3cda67a7"
   },
   "outputs": [],
   "source": [
    "# Main execution\n",
    "repo_url = \"https://github.com/educ8s/Python-Tetris-Game-Pygame\"  # Replace with actual repo\n",
    "repo_path = clone_repo(repo_url)\n",
    "files = traverse_files(repo_path, extensions=[\".py\"])  # Modify extensions as needed\n",
    "parser = load_tree_sitter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qW2Qm21gFPqt",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Step 2: Convert and Load Graph Data into NetworkX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SnGqBwYO49Kq",
    "outputId": "d223579f-7545-43a7-ec6d-b2dde594ddd2"
   },
   "outputs": [],
   "source": [
    "# 1. Load the dataset a NetworkX Graph\n",
    "# Reference: https://networkx.org/documentation/stable/reference/generated/networkx.convert_matrix.from_pandas_edgelist.html\n",
    "\n",
    "G = build_graph(files, parser)\n",
    "\n",
    "# Visualize graph\n",
    "print(files)\n",
    "print(G)\n",
    "print(\"Nodes:\", G.nodes(data=True))\n",
    "print(\"Edges:\", G.edges(data=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tAeb_z-kFPqu",
    "outputId": "8b25b5c2-4c7b-4cb6-e8cb-d45183627866"
   },
   "outputs": [],
   "source": [
    "# 2. Print the degree of one of the nodes\n",
    "\n",
    "print(G.degree('repo/main.py'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 730
    },
    "id": "EnZvgKKQFPqu",
    "outputId": "ada519e8-2f63-4107-fcec-baa40d9e4534"
   },
   "outputs": [],
   "source": [
    "# 3. Visualize the Graph\n",
    "\n",
    "plot_options = {\"node_size\": 10, \"with_labels\": False, \"width\": 0.15}\n",
    "pos = nx.spring_layout(G, iterations=15, seed=1721)\n",
    "fig, ax = plt.subplots(figsize=(15, 9))\n",
    "nx.draw_networkx(G, pos=pos, ax=ax, **plot_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jxHFUSJ0V4Ft"
   },
   "outputs": [],
   "source": [
    "def visualize_graph_3d(G):\n",
    "    pos = nx.spring_layout(G, dim=3, seed=42)  # Generate 3D positions\n",
    "\n",
    "    # Extract edge positions and midpoint labels\n",
    "    edge_x, edge_y, edge_z = [], [], []\n",
    "    annotations = []\n",
    "\n",
    "    for edge in G.edges():\n",
    "        x0, y0, z0 = pos[edge[0]]\n",
    "        x1, y1, z1 = pos[edge[1]]\n",
    "\n",
    "        # Edge lines\n",
    "        edge_x.extend([x0, x1, None])\n",
    "        edge_y.extend([y0, y1, None])\n",
    "        edge_z.extend([z0, z1, None])\n",
    "\n",
    "        # Midpoint of edge for labeling\n",
    "        mid_x, mid_y, mid_z = (x0 + x1) / 2, (y0 + y1) / 2, (z0 + z1) / 2\n",
    "        relation = G[edge[0]][edge[1]].get(\"relation\", \"\")\n",
    "\n",
    "        # Store annotation text\n",
    "        annotations.append(dict(\n",
    "            x=mid_x, y=mid_y, z=mid_z,\n",
    "            text=relation,\n",
    "            showarrow=False,\n",
    "            font=dict(size=10, color=\"black\")\n",
    "        ))\n",
    "\n",
    "    # Edge lines trace\n",
    "    edge_trace = go.Scatter3d(\n",
    "        x=edge_x, y=edge_y, z=edge_z,\n",
    "        line=dict(width=2, color='gray'),\n",
    "        hoverinfo='none',\n",
    "        mode='lines'\n",
    "    )\n",
    "\n",
    "    # Extract node positions\n",
    "    node_x, node_y, node_z = [], [], []\n",
    "    node_text = []\n",
    "    node_colors = {\n",
    "        \"file\": \"blue\",\n",
    "        \"class\": \"green\",\n",
    "        \"method\": \"orange\",\n",
    "        \"function\": \"red\",\n",
    "        \"variable\": \"purple\"\n",
    "    }\n",
    "    node_types = nx.get_node_attributes(G, \"type\")\n",
    "\n",
    "    for node in G.nodes():\n",
    "        x, y, z = pos[node]\n",
    "        node_x.append(x)\n",
    "        node_y.append(y)\n",
    "        node_z.append(z)\n",
    "        node_text.append(f\"{node} ({node_types.get(node, 'unknown')})\")\n",
    "\n",
    "    # Node trace\n",
    "    node_trace = go.Scatter3d(\n",
    "        x=node_x, y=node_y, z=node_z,\n",
    "        mode='markers+text',\n",
    "        marker=dict(\n",
    "            size=8,\n",
    "            color=[node_colors.get(node_types.get(n, \"gray\"), \"gray\") for n in G.nodes()],\n",
    "            opacity=0.8\n",
    "        ),\n",
    "        text=node_text,\n",
    "        hoverinfo='text'\n",
    "    )\n",
    "\n",
    "    # Create figure\n",
    "    fig = go.Figure(data=[edge_trace, node_trace])\n",
    "\n",
    "    # Add edge labels as annotations\n",
    "    for ann in annotations:\n",
    "        fig.add_trace(go.Scatter3d(\n",
    "            x=[ann[\"x\"]], y=[ann[\"y\"]], z=[ann[\"z\"]],\n",
    "            mode='text',\n",
    "            text=[ann[\"text\"]],\n",
    "            hoverinfo='text',\n",
    "            textfont=dict(size=10, color=\"black\")\n",
    "        ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=\"3D Code Structure Graph\",\n",
    "        showlegend=False,\n",
    "        scene=dict(\n",
    "            xaxis=dict(visible=False),\n",
    "            yaxis=dict(visible=False),\n",
    "            zaxis=dict(visible=False)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "-CMnb7hNWA01",
    "outputId": "cc9f4ed7-238c-492f-e453-e90c02401704"
   },
   "outputs": [],
   "source": [
    "# Visualiza the graph in 3d\n",
    "visualize_graph_3d(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DI6Kgw0AFPqu",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Step 3: Persist the Graph in ArangoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 242,
     "referenced_widgets": [
      "7f5c2648764b40d8bf1995f452980187",
      "9cfb085262a54f11aaac3c8924980395",
      "6567c3c7d8f34b41bf122a0d976e3610",
      "382ca131df5f45d4a12d72c4c7330b6f"
     ]
    },
    "id": "XuUiYHDDFPqu",
    "outputId": "400af3b1-ba46-477c-d462-f6fe203323dc"
   },
   "outputs": [],
   "source": [
    "# 1. Load the NetworkX Graph into ArangoDB\n",
    "\n",
    "G_adb = nxadb.DiGraph(\n",
    "    name=\"github\",\n",
    "    db=db,\n",
    "    incoming_graph_data=G,\n",
    "    write_batch_size=50000, # feel free to modify\n",
    "    overwrite_graph=True,\n",
    ")\n",
    "print(G_adb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O3ThlpALI5G9",
    "outputId": "aa008f0c-88ea-4815-b464-63d5e5297220"
   },
   "outputs": [],
   "source": [
    "# 2. Re-connect to the same Graph\n",
    "\n",
    "G_adb = nxadb.DiGraph(name=\"github\", db=db)\n",
    "\n",
    "print(G_adb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NKMcJ_wCFPqy",
    "outputId": "66a0cc62-8adf-4330-8e76-3d09f08d64cd"
   },
   "outputs": [],
   "source": [
    "# 3. Print the degree of a Node\n",
    "\n",
    "G_adb.degree('github_node/45')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B40xau3KFPqz",
    "outputId": "96f635b0-1d62-4b7d-bb6c-9eae4a0e59b2"
   },
   "outputs": [],
   "source": [
    "# 4. Query the Graph\n",
    "\n",
    "# Sample 3 nodes\n",
    "result = G_adb.query(\"\"\"\n",
    "    FOR node IN github_node\n",
    "        SORT RAND()\n",
    "        LIMIT 3\n",
    "        RETURN node\n",
    "\"\"\")\n",
    "\n",
    "print(list(result))\n",
    "print('-'*10)\n",
    "\n",
    "# Sample 3 edges\n",
    "result = G_adb.query(\"\"\"\n",
    "    FOR edge IN github_node_to_github_node\n",
    "        SORT RAND()\n",
    "        LIMIT 3\n",
    "        RETURN edge\n",
    "\"\"\")\n",
    "\n",
    "print(list(result))\n",
    "print('-'*10)\n",
    "\n",
    "# Traverse a node's 1-hop neighborhood\n",
    "result = G_adb.query(\"\"\"\n",
    "    FOR node, edge, path IN 1..1 ANY 'github_node/1' GRAPH github\n",
    "        LIMIT 1\n",
    "        RETURN path\n",
    "\"\"\")\n",
    "\n",
    "print(list(result))\n",
    "\n",
    "result = G_adb.query(\"\"\"\n",
    "    WITH github_node\n",
    "    FOR node IN github_node\n",
    "        FILTER node.type == \"method\" && node.name LIKE \"Game.%\"\n",
    "        RETURN node\n",
    "\"\"\")\n",
    "\n",
    "print(list(result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BJc6Q1Cm4yWf"
   },
   "outputs": [],
   "source": [
    "from arango import ArangoClient\n",
    "import networkx as nx\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def visualize_arangodb_graph_3d(db, graph_name):\n",
    "    # Fetch the ArangoDB graph\n",
    "    graph = db.graph(graph_name)\n",
    "\n",
    "    # Create a NetworkX graph\n",
    "    G = nx.Graph()\n",
    "\n",
    "    # Add nodes from all vertex collections\n",
    "    for vertex_collection_name in graph.vertex_collections():\n",
    "        collection = db.collection(vertex_collection_name)\n",
    "        for vertex in collection.all():\n",
    "            # Extract attributes (excluding system fields like '_key', '_id', etc.)\n",
    "            attrs = {k: v for k, v in vertex.items() if k not in ['_id', '_rev', '_key']}\n",
    "            G.add_node(vertex['_key'], **attrs)\n",
    "\n",
    "    # Add edges from all edge collections\n",
    "    for edge_definition in graph.edge_definitions():\n",
    "        edge_collection_name = edge_definition['edge_collection']\n",
    "        collection = db.collection(edge_collection_name)\n",
    "        for edge in collection.all():\n",
    "            # Extract '_from' and '_to' keys (format: \"collection/key\")\n",
    "            from_key = edge['_from'].split('/')[-1]\n",
    "            to_key = edge['_to'].split('/')[-1]\n",
    "            # Extract edge attributes (excluding system fields)\n",
    "            attrs = {k: v for k, v in edge.items() if k not in ['_id', '_rev', '_key', '_from', '_to']}\n",
    "            G.add_edge(from_key, to_key, **attrs)\n",
    "\n",
    "    # Generate 3D positions using NetworkX\n",
    "    visualize_graph_3d(G)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "kWMaDJJ45m3i",
    "outputId": "1d4ab965-22af-406c-cce2-c63a644be6b9"
   },
   "outputs": [],
   "source": [
    "visualize_arangodb_graph_3d(db, 'github')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bL_fwOpt5zzA",
    "outputId": "958dcf58-3f40-4ff1-ed91-25a96df70460"
   },
   "outputs": [],
   "source": [
    "# 5. Experimenting with different node keys\n",
    "\n",
    "print(G_adb.nodes[1])\n",
    "print(G_adb.nodes[\"1\"])\n",
    "print(G_adb.nodes[\"github_node/1\"])\n",
    "\n",
    "print('----')\n",
    "\n",
    "print(G_adb[0][1])\n",
    "print(G_adb[\"0\"][1])\n",
    "print(G_adb[\"github_node/0\"][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yl4fPMUIFPqz",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Step 4: Build the Agentic App with LangChain & LangGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nw6M5k8IFPqz"
   },
   "outputs": [],
   "source": [
    "# 1. Create the ArangoGraph LangChain wrapper\n",
    "\n",
    "arango_graph = ArangoGraph(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zGitgSvxFPqz",
    "outputId": "c9191f87-9dff-40cf-8c49-3da16a0707bc"
   },
   "outputs": [],
   "source": [
    "# 2. Define the llm object\n",
    "# Note: You can use any llm you want. I will be using DeepSeek for example.\n",
    "\n",
    "os.environ['DEEPSEEK_API_KEY'] ='APIKEY'\n",
    "\n",
    "llm = ChatDeepSeek(\n",
    "    model=\"deepseek-chat\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "llm.invoke(\"hello!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y1ZjSCRWzfm4"
   },
   "outputs": [],
   "source": [
    "class TimeoutError(Exception):\n",
    "    \"\"\"Custom timeout exception\"\"\"\n",
    "    pass\n",
    "\n",
    "def execute_with_timeout(func, timeout=30):\n",
    "    \"\"\"Executes a function with a timeout using threading.Timer\"\"\"\n",
    "    result = [None]\n",
    "    error = [None]\n",
    "\n",
    "    def wrapper():\n",
    "        try:\n",
    "            result[0] = func()\n",
    "        except Exception as e:\n",
    "            error[0] = str(e)\n",
    "\n",
    "    thread = threading.Thread(target=wrapper)\n",
    "    thread.start()\n",
    "    thread.join(timeout)\n",
    "\n",
    "    if thread.is_alive():\n",
    "        return \"ERROR: Execution timed out after {} seconds.\".format(timeout)\n",
    "\n",
    "    if error[0]:\n",
    "        return \"ERROR: \" + error[0]\n",
    "\n",
    "    return result[0]\n",
    "\n",
    "@tool(return_direct=True)\n",
    "def text_to_aql_to_text(query: str):\n",
    "    \"\"\"This tool is available to invoke the\n",
    "      ArangoGraphQAChain object, which enables you to\n",
    "      translate a Natural Language Query into AQL, execute\n",
    "      the query, and translate the result back into Natural Language.\n",
    "    \"\"\"\n",
    "\n",
    "    def process_query():\n",
    "        llm = ChatDeepSeek(\n",
    "            model=\"deepseek-chat\",\n",
    "            temperature=0\n",
    "        )\n",
    "\n",
    "        chain = ArangoGraphQAChain.from_llm(\n",
    "            llm=llm,\n",
    "            graph=arango_graph,\n",
    "            verbose=True,\n",
    "            allow_dangerous_requests=True\n",
    "        )\n",
    "\n",
    "        result = chain.invoke(query)\n",
    "        return str(result[\"result\"])\n",
    "\n",
    "    return execute_with_timeout(process_query, timeout=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j-KCUY4lw9uB"
   },
   "outputs": [],
   "source": [
    "@tool(return_direct=True)\n",
    "def text_to_nx_algorithm_to_text(query):\n",
    "    \"\"\"This tool is available to invoke a NetworkX Algorithm on\n",
    "      the ArangoDB Graph. You are responsible for accepting the\n",
    "      Natural Language Query, establishing which algorithm needs to\n",
    "      be executed, executing the algorithm, and translating the results back\n",
    "      to Natural Language, with respect to the original query.\n",
    "      If the query (e.g traversals, shortest path, etc.) can be solved using the Arango Query Language, then do not use\n",
    "      this tool.\n",
    "    \"\"\"\n",
    "\n",
    "    # Store the current code in a higher scope variable that all nested functions can access\n",
    "    current_code = {\"value\": None}\n",
    "\n",
    "    def generate_networkx_code():\n",
    "        llm = ChatDeepSeek(model=\"deepseek-chat\", temperature=0)\n",
    "\n",
    "        # Extract and provide graph schema information\n",
    "        node_types = set(data.get(\"type\", \"unknown\") for _, data in G_adb.nodes(data=True))\n",
    "        edge_relations = set(data.get('relation', 'unknown') for _, _, data in G_adb.edges(data=True))\n",
    "\n",
    "        # Sample nodes and their relationships for context\n",
    "        sample_nodes = {}\n",
    "        for node, data in list(G_adb.nodes(data=True))[:10]:  # Limit to 10 samples for brevity\n",
    "            sample_nodes[node] = {\n",
    "                \"type\": data.get(\"type\", \"unknown\"),\n",
    "                \"properties\": {k: v for k, v in data.items() if k != \"type\"},\n",
    "                \"outgoing_relations\": [],\n",
    "                \"incoming_relations\": []\n",
    "            }\n",
    "\n",
    "        # Add relationship information for the sample nodes\n",
    "        for source, target, data in G_adb.edges(data=True):\n",
    "            relation = data.get(\"relation\", \"connected_to\")\n",
    "            if source in sample_nodes:\n",
    "                sample_nodes[source][\"outgoing_relations\"].append({\n",
    "                    \"target\": target,\n",
    "                    \"relation\": relation\n",
    "                })\n",
    "            if target in sample_nodes:\n",
    "                sample_nodes[target][\"incoming_relations\"].append({\n",
    "                    \"source\": source,\n",
    "                    \"relation\": relation\n",
    "                })\n",
    "\n",
    "        # Prepare the graph context\n",
    "        graph_context = {\n",
    "            \"node_types\": list(node_types),\n",
    "            \"edge_relations\": list(edge_relations),\n",
    "            \"sample_structure\": sample_nodes\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            text_to_nx = llm.invoke(f\"\"\"\n",
    "\n",
    "            I have a NetworkX DiGraph called `G_adb`. It has the following schema: {arango_graph.schema}\n",
    "\n",
    "            Node Types: {graph_context[\"node_types\"]}\n",
    "            Edge Relations: {graph_context[\"edge_relations\"]}\n",
    "\n",
    "            Sample Graph Structure:\n",
    "            ```\n",
    "            {sample_nodes}\n",
    "            ```\n",
    "\n",
    "            The graph represents a code base where:\n",
    "            - Files contain classes and functions\n",
    "            - Classes contain methods\n",
    "            - Functions and methods can call other functions or methods\n",
    "            - Classes can inherit from other classes\n",
    "\n",
    "            I have the following graph analysis query: {query}.\n",
    "\n",
    "            Generate the Python Code required to answer the query using the `G_adb` object.\n",
    "\n",
    "            Be very precise on the NetworkX algorithm you select to answer this query. Think step by step.\n",
    "\n",
    "            Only assume that networkx is installed, and other base python dependencies.\n",
    "\n",
    "            Always set the last variable as `FINAL_RESULT`, which represents the answer to the original query.\n",
    "\n",
    "            Only provide python code that I can directly execute via `exec()`. Do not provide any instructions.\n",
    "\n",
    "            Make sure that `FINAL_RESULT` stores a short & consice answer. Avoid setting this variable to a long sequence.\n",
    "\n",
    "            Your code:\n",
    "            \"\"\").content\n",
    "        except Exception as e:\n",
    "            return f\"Failed to generate NetworkX code: {str(e)}\"\n",
    "\n",
    "        # Ensure only Python code is extracted and remove unwanted characters\n",
    "        code_cleaned = re.sub(r\"^```python\\n|```$\", \"\", text_to_nx, flags=re.MULTILINE).strip()\n",
    "        # Replace smart quotes with standard quotes\n",
    "        code_cleaned = code_cleaned.replace(\"’\", \" \")\n",
    "        return code_cleaned\n",
    "\n",
    "    # Get initial code\n",
    "    initial_code = execute_with_timeout(generate_networkx_code, timeout=60)\n",
    "    if \"ERROR\" in initial_code:\n",
    "        return initial_code\n",
    "\n",
    "    # Store the initial code in our shared dictionary\n",
    "    current_code[\"value\"] = initial_code\n",
    "\n",
    "    def generate_networkx_code_with_feedback(error_message):\n",
    "        llm = ChatDeepSeek(model=\"deepseek-chat\", temperature=0)\n",
    "        try:\n",
    "            text_to_nx = llm.invoke(f\"\"\"\n",
    "            I attempted to execute the following ArangoDB code, but it failed:\n",
    "            ```\n",
    "            {current_code[\"value\"]}\n",
    "            ```\n",
    "            The error encountered was: {error_message}\n",
    "\n",
    "            Remember the graph represents a code base where:\n",
    "            - Files contain classes and functions\n",
    "            - Classes contain methods\n",
    "            - Functions and methods can call other functions or methods\n",
    "            - Classes can inherit from other classes\n",
    "\n",
    "            Generate the Python Code required to answer the query using the `G_adb` object.\n",
    "\n",
    "            Be very precise on the NetworkX algorithm you select to answer this query. Think step by step.\n",
    "\n",
    "            Only assume that networkx is installed, and other base python dependencies.\n",
    "\n",
    "            Always set the last variable as `FINAL_RESULT`, which represents the answer to the original query.\n",
    "\n",
    "            Only provide python code that I can directly execute via `exec()`. Do not provide any instructions.\n",
    "\n",
    "            Make sure that `FINAL_RESULT` stores a short & consice answer. Avoid setting this variable to a long sequence.\n",
    "\n",
    "            Your code:\n",
    "            \"\"\").content\n",
    "        except Exception as e:\n",
    "            return f\"Failed to generate corrected NetworkX code: {str(e)}\"\n",
    "\n",
    "        # Cleanup the generated code\n",
    "        code_cleaned = re.sub(r\"^```python\\n|```$\", \"\", text_to_nx, flags=re.MULTILINE).strip()\n",
    "        code_cleaned = code_cleaned.replace(\"’\", \" \")\n",
    "        return code_cleaned\n",
    "\n",
    "    def execute_networkx_code(max_retries=3):\n",
    "        global_vars = {\"G_adb\": G_adb, \"nx\": nx}\n",
    "        local_vars = {}\n",
    "\n",
    "        for attempt in range(max_retries):\n",
    "            print(f\"\\nAttempt {attempt + 1} - Executing NetworkX Code:\\n{current_code['value']}\\n\")\n",
    "\n",
    "            try:\n",
    "                exec(current_code[\"value\"], global_vars, local_vars)\n",
    "                if \"FINAL_RESULT\" in local_vars:\n",
    "                    return local_vars[\"FINAL_RESULT\"]\n",
    "                return \"Execution succeeded but did not return a FINAL_RESULT.\"\n",
    "            except SyntaxError as e:\n",
    "                error_msg = f\"Syntax Error in generated code: {str(e)}\"\n",
    "            except Exception as e:\n",
    "                error_msg = f\"Execution Error: {str(e)}\"\n",
    "\n",
    "            print(f\"Error encountered: {error_msg}\")\n",
    "\n",
    "            # Send feedback and request a revised version of the code\n",
    "            new_code = generate_networkx_code_with_feedback(error_msg)\n",
    "            if isinstance(new_code, str) and new_code.startswith(\"Failed to generate\"):\n",
    "                return f\"Retried {attempt + 1} times, but no valid code was generated: {new_code}\"\n",
    "\n",
    "            # Replace with new generated code and retry\n",
    "            current_code[\"value\"] = new_code\n",
    "\n",
    "        return \"All retries failed. Unable to execute NetworkX code.\"\n",
    "\n",
    "    final_result = execute_with_timeout(execute_networkx_code, timeout=60)\n",
    "    if \"ERROR\" in str(final_result):\n",
    "        return final_result\n",
    "\n",
    "    def formulate_final_response():\n",
    "        llm = ChatDeepSeek(model=\"deepseek-chat\", temperature=0)\n",
    "\n",
    "        # Get relevant node types and relationships for context in the response\n",
    "        node_types = set(data['type'] for _, data in G_adb.nodes(data=True))\n",
    "        edge_relations = set(data.get('relation', 'unknown') for _, _, data in G_adb.edges(data=True))\n",
    "\n",
    "        response = llm.invoke(f\"\"\"\n",
    "            Based on my query: {query}\n",
    "\n",
    "            The graph represents a code base where:\n",
    "            - Files contain classes and functions\n",
    "            - Classes contain methods\n",
    "            - Functions and methods can call other functions or methods\n",
    "            - Classes can inherit from other classes\n",
    "\n",
    "            Node types in the graph: {list(node_types)}\n",
    "            Edge relationships in the graph: {list(edge_relations)}\n",
    "\n",
    "            The calculated result is: {final_result}\n",
    "\n",
    "            Generate a short and concise response that explains the result in the context of the code structure.\n",
    "        \"\"\").content\n",
    "        return response\n",
    "\n",
    "    return execute_with_timeout(formulate_final_response, timeout=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RtHBiEzJ3l9y"
   },
   "outputs": [],
   "source": [
    "# 6. Create the Agentic Application\n",
    "\n",
    "# Define available tools\n",
    "tools = [text_to_nx_algorithm_to_text, text_to_aql_to_text]\n",
    "\n",
    "def query_graph(query):\n",
    "    \"\"\"Executes a query using the most appropriate tool (AQL or NetworkX) and formats the result.\"\"\"\n",
    "\n",
    "    llm = ChatDeepSeek(\n",
    "        model=\"deepseek-chat\",\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "\n",
    "    # If the tool selection fails, let the agent handle it\n",
    "    app = create_react_agent(llm, tools)\n",
    "    final_state = app.invoke({\"messages\": [{\"role\": \"user\", \"content\": query}]})\n",
    "    result = final_state[\"messages\"][-1].content if \"messages\" in final_state else \"ERROR: No response\"\n",
    "\n",
    "    # Debugging output\n",
    "    print(f\"Raw result: {result}\")\n",
    "\n",
    "    # Format the output\n",
    "    if isinstance(result, dict) and \"result\" in result:\n",
    "        return result[\"result\"]\n",
    "    elif isinstance(result, str):\n",
    "        return result.strip()\n",
    "    else:\n",
    "        return \"ERROR: Unexpected response format\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a5EcHoX5FPq0"
   },
   "outputs": [],
   "source": [
    "# 7. Experiment with example queries\n",
    "# Note: Some may work, some may not!\n",
    "\n",
    "query = \"Are there isolated nodes?\"\n",
    "query = \"Which node has the highest betweenness centrality score? Use a k value of 10\"\n",
    "query = \"Who is connected to Node 0?\"\n",
    "query = \"What is the shortest path from Node 0 to Node 1?\"\n",
    "query = \"Update node 0 to have attribute foo=bar\"\n",
    "query = \"Is the graph fully connected?\"\n",
    "query = \"What is the average degree of nodes?\"\n",
    "query = \"Are there nodes that, if removed, would fragment the network?\"\n",
    "query = \"Which users are outliers in terms of connections?\"\n",
    "query = \"Which nodes are the most connected?\"\n",
    "query = \"How strongly connected is the network? Used connected components\"\n",
    "query = \"Fetch the highest pagerank node and value\"\n",
    "query = \"Who is the most influential node?\"\n",
    "query = \"Who is the most popular person in the Graph? Explain why\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 348
    },
    "id": "LOW3Ouq1FPq0",
    "outputId": "ef158758-e258-4637-9931-4f14e473a975"
   },
   "outputs": [],
   "source": [
    "query_graph(\"Which file has the most methods\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "2R4B6D96Vq6C",
    "outputId": "7fb7eb46-3467-40ac-a967-f1afb0a4f4e4"
   },
   "outputs": [],
   "source": [
    "query_graph(\"Which is the most called function in the network?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 628
    },
    "id": "gkFJmsAebmBO",
    "outputId": "16c796f6-86f4-4ae4-e1bb-14d849b34fd3"
   },
   "outputs": [],
   "source": [
    "query_graph(\"Return all methods connected to Node 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 368
    },
    "id": "23gn7Y2mE4AZ",
    "outputId": "68228d34-7461-487f-928c-542fda532306"
   },
   "outputs": [],
   "source": [
    "query_graph(\"Does Node 1 contains a method with the name reset?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 333
    },
    "id": "jK3LVyMXGhfd",
    "outputId": "41546291-71ec-4acf-bb5e-ca93508f4c48"
   },
   "outputs": [],
   "source": [
    "query_graph(\"find node with name Game\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 403
    },
    "id": "KpWpnnSQFPq1",
    "outputId": "47a8a90a-3e92-4e6a-a2c0-4c75d555b3f4"
   },
   "outputs": [],
   "source": [
    "query_graph(\"Which functions/ methods call connected to Node 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 368
    },
    "id": "DFaiDNArk3uX",
    "outputId": "93765e9b-a117-432d-8d71-24a4bbd396ee"
   },
   "outputs": [],
   "source": [
    "query_graph(\"What design patterns are used in this repo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "h3pzHLF9FPq1",
    "outputId": "cbf5606b-70e2-4521-d30a-68bd05054486"
   },
   "outputs": [],
   "source": [
    "query_graph(\"How strongly connected is the network? Used connected components\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ekj9kse2FPq1",
    "outputId": "1382d8c7-d84b-4c1c-dc7e-62c0efb7769e"
   },
   "outputs": [],
   "source": [
    "# 8. (Optional) Set up UI via Gradio\n",
    "\n",
    "%pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 611
    },
    "id": "6zo8fGy4FPq1",
    "outputId": "d2623d0f-dc61-4823-f7ae-b0d7c96fc1e3"
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "gr.Interface(fn=query_graph, inputs=\"text\", outputs=\"text\").launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "L4nmLCFf3HoC",
    "hoyxgmOz3CwF",
    "vrB4FpB63yEF",
    "5fsZEyyh3F87",
    "VE6lCtDb6KGw"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
